{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External LIbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Cleaned and Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = pd.read_csv('../data/Model_Benchmarks_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test = pd.read_csv('../data/Model_Benchmarks_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['overall_qual', 'total_sf','neighborhood', 'exter_qual', 'bsmt_qual', 'kitchen_qual', 'gr_liv_area',\n",
    "            'garage_cars', 'garage_finish','fireplace_qu', 'full_bath', 'foundation', 'garage_type','mas_vnr_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using same features as previously used in linear regression \n",
    "- Once ran through regularization regression models (lasso, ridge, & Elastic net) features with little affect will be thrown out or reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_train[features]\n",
    "X = sm.add_constant(X)\n",
    "y =  clean_train[['saleprice']]\n",
    "X_kaggle_test = clean_test[features]\n",
    "X_kaggle_test =sm.add_constant(X_kaggle_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state = 69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming and Fitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting and Transforming Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias = False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "X_kaggle_test_poly = poly.fit_transform(X_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train_poly)\n",
    "\n",
    "X_train_poly_sc = ss.transform(X_train_poly)\n",
    "X_test_poly_sc = ss.transform(X_test_poly)\n",
    "X_kaggle_test_poly_sc = ss.transform(X_kaggle_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting four different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Cross Value Score  0.877175744581021\n",
      "Lasso Cross Value Score  0.8859616591548252\n",
      "Ridge Cross Value Score  0.888248071988912\n",
      "Elastic Net Cross Value Score  0.8835425721308179\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lasso = LassoCV()\n",
    "ridge = RidgeCV()\n",
    "en = ElasticNetCV(l1_ratio = [.1 , .5 , .7 , .9 , .95, .99, .1])\n",
    "\n",
    "kf = KFold(n_splits = 7, shuffle = True, random_state = 69)\n",
    "\n",
    "lr_cv = cross_val_score(lr, X_train_poly_sc, y_train, cv=kf).mean()\n",
    "lasso_cv = cross_val_score(lasso, X_train_poly_sc, y_train, cv=kf).mean()\n",
    "ridge_cv = cross_val_score(ridge, X_train_poly_sc, y_train, cv=kf).mean()\n",
    "en_cv = cross_val_score(en, X_train_poly_sc, y_train, cv=kf).mean()\n",
    "\n",
    "print('Linear Cross Value Score ', lr_cv)\n",
    "print('Lasso Cross Value Score ', lasso_cv)\n",
    "print('Ridge Cross Value Score ', ridge_cv)\n",
    "print('Elastic Net Cross Value Score ', en_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examining these cross value scores it is clear that linear regression is obsolete. \n",
    "- Ridge has the highest cross value score, just barely beating out lasso and ridge.\n",
    "    - Ridge will be used going foward on kaggle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Score Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Cross Value Score  0.8913763405052156\n"
     ]
    }
   ],
   "source": [
    "ridge_cv = cross_val_score(en, X_test_poly_sc, y_test, cv=kf).mean()\n",
    "print('Ridge Cross Value Score ', ridge_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "- When ran on the test data the cross value score is almost identical\n",
    "- model is not underfit or overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 0.1], max_iter=1000,\n",
       "       n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "       precompute='auto', random_state=None, selection='cyclic',\n",
       "       tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.fit(X_train_poly_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = en.predict(X_kaggle_test_poly_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2658</td>\n",
       "      <td>144117.815184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2718</td>\n",
       "      <td>198012.505168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2414</td>\n",
       "      <td>192359.473185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>123903.686710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>178795.491162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  2658  144117.815184\n",
       "1  2718  198012.505168\n",
       "2  2414  192359.473185\n",
       "3  1989  123903.686710\n",
       "4   625  178795.491162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame([], columns = ['Id', 'SalePrice'])\n",
    "predictions['Id'] = clean_test['id']\n",
    "predictions['SalePrice'] = y_test_preds\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2049.000000\n",
       "mean     181479.018058\n",
       "std       79295.913255\n",
       "min       12789.000000\n",
       "25%      129800.000000\n",
       "50%      162500.000000\n",
       "75%      214000.000000\n",
       "max      611657.000000\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train['saleprice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       879.000000\n",
       "mean     179895.477997\n",
       "std       74958.985588\n",
       "min       60109.822344\n",
       "25%      125967.770346\n",
       "50%      161359.192224\n",
       "75%      211869.984896\n",
       "max      646995.948962\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.428990\n",
       "mean     0.991274\n",
       "std      0.945307\n",
       "min      4.700119\n",
       "25%      0.970476\n",
       "50%      0.992980\n",
       "75%      0.990047\n",
       "max      1.057776\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['SalePrice'].describe()/clean_train['saleprice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('../data/predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
